{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d47a2a-f643-410f-8c69-1c5a362a834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54135f87-fe47-4796-865c-8b483fe57967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Verify CUDA\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e522d5-eb77-434a-a7f5-d78fd3fe362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to dataset\n",
    "datasetDir = 'trainData/blurDataset'\n",
    "categories = ['defocused_blurred', 'motion_blurred', 'sharp']\n",
    "\n",
    "# Function to load images based on the folder\n",
    "def loadImages(category, imgSize=(224, 224)):\n",
    "    data = []\n",
    "    categoryPath = os.path.join(datasetDir, category)\n",
    "    for imgName in os.listdir(categoryPath):\n",
    "        imgPath = os.path.join(categoryPath, imgName)\n",
    "        image = cv2.imread(imgPath)\n",
    "        image = cv2.resize(image, imgSize)\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "    return np.array(data)\n",
    "\n",
    "defocusedBlurredImages = loadImages('defocused_blurred')\n",
    "motionBlurredImages = loadImages('motion_blurred')\n",
    "sharpImages = loadImages('sharp')\n",
    "\n",
    "# Label creation\n",
    "labels = np.concatenate([\n",
    "    np.zeros(len(defocusedBlurredImages)),  # Label: 0 for defocused_blurred\n",
    "    np.ones(len(motionBlurredImages)),      # Label: 1 for motion_blurred\n",
    "    np.full(len(sharpImages), 2)            # Label: 2 for sharp\n",
    "])\n",
    "\n",
    "# Combine and normalize the dataset\n",
    "images = np.concatenate([defocusedBlurredImages, motionBlurredImages, sharpImages])\n",
    "images = images / 255.0  # Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a27a169-7d48-45ec-85d4-94ce64d208a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the x and y test and train values using an 80:20 ratio\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b657a2-0bae-4f95-a9f3-32bad25b9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 without the top layers\n",
    "baseModel = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers for classification\n",
    "x = baseModel.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)  # 3 classes: defocused, motion blurred, sharp\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09801cdd-4816-4446-9a4b-fd94b12edf07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 498ms/step - accuracy: 0.5920 - loss: 0.9458 - val_accuracy: 0.7560 - val_loss: 0.6348\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 438ms/step - accuracy: 0.8888 - loss: 0.3330 - val_accuracy: 0.7560 - val_loss: 0.5997\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 450ms/step - accuracy: 0.9367 - loss: 0.2021 - val_accuracy: 0.8095 - val_loss: 0.5841\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 451ms/step - accuracy: 0.9879 - loss: 0.0992 - val_accuracy: 0.8214 - val_loss: 0.5780\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.9963 - loss: 0.0617 - val_accuracy: 0.8214 - val_loss: 0.5779\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0469 - val_accuracy: 0.8274 - val_loss: 0.5873\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.8274 - val_loss: 0.6106\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9998 - loss: 0.0232 - val_accuracy: 0.8214 - val_loss: 0.6315\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 453ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.8333 - val_loss: 0.6421\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.8333 - val_loss: 0.6767\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(xTrain, yTrain, validation_data=(xVal, yVal), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d001635e-fef1-4573-a7e2-577fafa351ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - accuracy: 0.8376 - loss: 0.5471\n",
      "Test accuracy: 0.8190\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "loss, accuracy = model.evaluate(xTest, yTest)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a953b525-36ef-41ee-8159-f14a4cfdd0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
     ]
    }
   ],
   "source": [
    "# Create a concrete function from the model\n",
    "runModel = tf.function(lambda x: model(x))\n",
    "concreteFunc = runModel.get_concrete_function(tf.TensorSpec([None, 224, 224, 3], model.inputs[0].dtype))\n",
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([concreteFunc])\n",
    "tfliteModel = converter.convert()\n",
    "\n",
    "# Save the converted model\n",
    "with open('blur_model.tflite', 'wb') as f:\n",
    "    f.write(tfliteModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797e9cc-96f1-4bca-a14a-be97feb49868",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418bd9bb-0d79-4b60-ad5f-bac1a3fc6157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: sharp\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"blur_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "inputDetails = interpreter.get_input_details()\n",
    "outputDetails = interpreter.get_output_details()\n",
    "\n",
    "# Load and preprocess your image\n",
    "def preprocessImage(imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype(np.float32)\n",
    "    image = image / 255.0  # Normalize\n",
    "    return np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "imagePath = 'testData/blurTest/clear1.jpg'\n",
    "inputData = preprocessImage(imagePath)\n",
    "\n",
    "# Set the input tensor\n",
    "interpreter.set_tensor(inputDetails[0]['index'], inputData)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output\n",
    "outputData = interpreter.get_tensor(outputDetails[0]['index'])\n",
    "predictedClass = np.argmax(outputData)\n",
    "classNames = ['defocused_blurred', 'motion_blurred', 'sharp']\n",
    "\n",
    "# Output the predicted class\n",
    "print(f\"Predicted class: {classNames[predictedClass]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b981e4-c6bc-4d03-be9a-12d3a77d97fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
